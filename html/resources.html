<!DOCTYPE html lang="en">
<head>
<title>Device Resources</title>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link href="../css/style.css" rel="stylesheet" type="text/css" />

  <meta name="description" content="">
  <meta name="keywords" content="">
  <meta name="author" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="../css/bootstrap.css" />

</head>
<body>

<h1>Web Resources</h1>

<p class="foo">
<a href="#a">Android Unity Development</a> | 
<a href="#b">Look into My Eyes: Face-screen Distance Detection</a> | 
<a href="#c">How Blind People Use Smartphones</a> |
<a href="../index.html">Profile</a>
</p>

<ol>

<li>
<p id="a">
<a href="https://developer.android.com/games/develop/build-in-unity">Android Documentation: Build your game in Unity</a><br />
I have used Unity for many years and have wanted to work with its Android development. This link provides a guide to how to get started using Unity for Android.
The guide itself is straightforward and easy to follow. Hopefully using Unity isn't straying too far from our course outcomes; in older versions of Unity you could imbed a game into a web page.<br />
Rating: 5 out of 5
<br />
<a href="https://docs.unity3d.com/Packages/com.unity.inputsystem@0.9/manual/Sensors.html">Unity Sensor Support</a><br />
Continuing on this I have been curious of how to implement the sensor information in game or app dev in Unity.
This page of the manual lists quite a few interesting ones including gravity and humidity sensors. I do wish it had more detailed descriptions of the functionality, however.
Seeing these inspires me to what possibilities I could make in Unity.
<br />
Rating: 4 out of 5
</p>
</li>

<li>
<p id="b">
<a href="https://arxiv.org/pdf/1612.04131.pdf">Look into My Eyes: Fine-grained Detection of Face-screen Distance on Smartphones</a><br />
This paper looks into providing face-screen distance measurement for devices without internal or external sensors that use things like infrared or ultrasonic. The method they use “Look into My Eyes” or LIME uses the camera and accelerometer, the first of which is almost universal in smartphones.
The most interesting aspect of this to me was the dynamic font sizing which seemed like it had good applications in accessibility support and responsive web design.
<br />
Rating: 4 out of 5

</p>

</li>

<li>
<p id="c">
<a href="https://www.insider.com/how-blind-people-use-smartphones-2017-2">How Blind People Use Smartphones</a><br />
This article goes into accessibility for blind and low-vision users. It has a nice video demonstrating how an iPhone is used, clearly showing the variety of touch sensors and pressure sensitivity needed to perform a wide variety of tasks.
It also brings up braille displays, which were what I had originally started looking for. I would say I would have liked more in-depth info, but the video example was very informative on its own.
<br />
Rating: 4.5 out of 5
</p>
</li>

</ol>

</body>
</html>

